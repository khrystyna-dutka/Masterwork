# ml-service/test_model.py
from utils.db_helper import DatabaseHelper
from data.preprocessor import DataPreprocessor
from models.lstm_model import LSTMForecastModel
from config import Config
import numpy as np
from sklearn.model_selection import train_test_split

def test_model_training():
    """–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ"""
    
    print("=" * 60)
    print("üß™ –¢–ï–°–¢–£–í–ê–ù–ù–Ø LSTM –ú–û–î–ï–õ–Ü")
    print("=" * 60)
    
    # –í–∏–±—Ä–∞—Ç–∏ —Ä–∞–π–æ–Ω –¥–ª—è —Ç–µ—Å—Ç—É
    district_id = 1
    
    print(f"\nüìå –†–∞–π–æ–Ω: {Config.DISTRICTS[district_id-1]['name']} (ID: {district_id})")
    
    # –ö—Ä–æ–∫ 1: –û—Ç—Ä–∏–º–∞—Ç–∏ –¥–∞–Ω—ñ
    print("\n1Ô∏è‚É£ –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –ë–î...")
    db = DatabaseHelper()
    df = db.get_historical_data(district_id, days=365)
    
    if len(df) < Config.SEQUENCE_LENGTH + 1:
        print(f"\n‚ö†Ô∏è –ù–ï–î–û–°–¢–ê–¢–ù–¨–û –î–ê–ù–ò–•!")
        print(f"   –ü–æ—Ç—Ä—ñ–±–Ω–æ –º—ñ–Ω—ñ–º—É–º: {Config.SEQUENCE_LENGTH + 1} –∑–∞–ø–∏—Å—ñ–≤")
        print(f"   –Ñ –∑–∞—Ä–∞–∑: {len(df)} –∑–∞–ø–∏—Å—ñ–≤")
        return
    
    print(f"‚úÖ –û—Ç—Ä–∏–º–∞–Ω–æ {len(df)} –∑–∞–ø–∏—Å—ñ–≤")
    
    if len(df) < 500:
        print(f"\n‚ö†Ô∏è –£–í–ê–ì–ê: –î–∞–Ω–∏—Ö –º–∞–ª–æ –¥–ª—è —è–∫—ñ—Å–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è!")
        print(f"   –ú–æ–¥–µ–ª—å –±—É–¥–µ –Ω–∞–≤—á–µ–Ω–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó...\n")
    
    # –ö—Ä–æ–∫ 2: –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ
    print("\n2Ô∏è‚É£ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö...")
    preprocessor = DataPreprocessor(district_id)
    prepared_data = preprocessor.prepare_data(df)
    
    # –ö—Ä–æ–∫ 3: –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
    print("\n3Ô∏è‚É£ –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö...")
    normalized_data = preprocessor.normalize_data(prepared_data.values, fit=True)
    
    # –ö—Ä–æ–∫ 4: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π
    print("\n4Ô∏è‚É£ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π –¥–ª—è LSTM...")
    X, y = preprocessor.create_sequences(normalized_data, Config.SEQUENCE_LENGTH)
    
    # –ö—Ä–æ–∫ 5: –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ train/val
    print("\n5Ô∏è‚É£ –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ train/val...")
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, shuffle=False
    )
    
    print(f"   Train: {len(X_train)} –∑—Ä–∞–∑–∫—ñ–≤")
    print(f"   Val: {len(X_val)} –∑—Ä–∞–∑–∫—ñ–≤")
    
    # –ö—Ä–æ–∫ 6: –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    print("\n6Ô∏è‚É£ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è LSTM –º–æ–¥–µ–ª—ñ...")
    model = LSTMForecastModel(district_id)
    model.build_model(input_shape=(X_train.shape[1], X_train.shape[2]))
    
    # –ö—Ä–æ–∫ 7: –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
    print("\n7Ô∏è‚É£ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ...")
    print("   ‚è≥ –¶–µ –º–æ–∂–µ –∑–∞–π–Ω—è—Ç–∏ 1-3 —Ö–≤–∏–ª–∏–Ω–∏...")
    
    y_train_dict = {
        'pm25': y_train[:, 0],
        'pm10': y_train[:, 1],
        'no2': y_train[:, 2],
        'so2': y_train[:, 3],
        'co': y_train[:, 4],
        'o3': y_train[:, 5]
    }
    
    y_val_dict = {
        'pm25': y_val[:, 0],
        'pm10': y_val[:, 1],
        'no2': y_val[:, 2],
        'so2': y_val[:, 3],
        'co': y_val[:, 4],
        'o3': y_val[:, 5]
    }
    
    history = model.train(
        X_train, y_train_dict,
        X_val, y_val_dict,
        epochs=20,
        batch_size=8
    )
    
    # –ö—Ä–æ–∫ 8: –¢–µ—Å—Ç–æ–≤–∏–π –ø—Ä–æ–≥–Ω–æ–∑
    print("\n8Ô∏è‚É£ –¢–µ—Å—Ç–æ–≤–∏–π –ø—Ä–æ–≥–Ω–æ–∑...")
    test_sequence = X_val[0]
    predictions = model.model.predict(test_sequence.reshape(1, *test_sequence.shape), verbose=0)
    
    # predictions[0] = pm25, predictions[1] = pm10, —ñ —Ç.–¥.
    # –í—ñ–∑—å–º–µ–º–æ PM2.5 —Ç–∞ –¥–µ–Ω–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ
    pm25_pred_norm = predictions[0][0][0]
    pm25_actual_norm = y_val[0][0]
    
    # –ü—Ä–æ—Å—Ç–∏–π —Å–ø–æ—Å—ñ–± –¥–µ–Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó - —Å—Ç–≤–æ—Ä–∏—Ç–∏ —Ñ–µ–π–∫–æ–≤–∏–π –≤–µ–∫—Ç–æ—Ä
    fake_vector_pred = np.zeros((1, 8))
    fake_vector_pred[0, 0] = pm25_pred_norm  # PM2.5
    fake_vector_pred[0, 1:] = 0.5  # –Ü–Ω—à—ñ - —Å–µ—Ä–µ–¥–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    
    fake_vector_actual = np.zeros((1, 8))
    fake_vector_actual[0, 0] = pm25_actual_norm
    fake_vector_actual[0, 1:] = 0.5
    
    # –î–µ–Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
    pm25_pred_real = preprocessor.inverse_transform(fake_vector_pred)[0, 0]
    pm25_actual_real = preprocessor.inverse_transform(fake_vector_actual)[0, 0]
    
    print(f"\n   üîÆ –ü—Ä–æ–≥–Ω–æ–∑ PM2.5: {pm25_pred_real:.2f} Œºg/m¬≥")
    print(f"   ‚úÖ –§–∞–∫—Ç–∏—á–Ω–∏–π PM2.5: {pm25_actual_real:.2f} Œºg/m¬≥")
    print(f"   üìä –†—ñ–∑–Ω–∏—Ü—è: {abs(pm25_pred_real - pm25_actual_real):.2f} Œºg/m¬≥")
    
    # –ö—Ä–æ–∫ 9: –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 24 –≥–æ–¥–∏–Ω–∏
    print("\n9Ô∏è‚É£ –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 24 –≥–æ–¥–∏–Ω–∏ –≤–ø–µ—Ä–µ–¥...")
    try:
        future_predictions = model.predict_future(X_val[-1], n_hours=24)
        print(f"   ‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {len(future_predictions)} –≥–æ–¥–∏–Ω")
        print(f"   üìä –°–µ—Ä–µ–¥–Ω—î PM2.5: {future_predictions['pm25'].mean():.2f} Œºg/m¬≥")
    except Exception as e:
        print(f"   ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑—É: {e}")
    
    # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –º–æ–¥–µ–ª—å
    print("\n" + "=" * 60)
    print("‚úÖ –¢–ï–°–¢–£–í–ê–ù–ù–Ø –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 60)
    print(f"\nüìã –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {model.model_path}")
    print(f"üìã Scaler –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {preprocessor.scaler_path}")
    print("\n‚ö†Ô∏è –í–ê–ñ–õ–ò–í–û:")
    print("   –ú–æ–¥–µ–ª—å –Ω–∞–≤—á–µ–Ω–∞ –Ω–∞ –º–∞–ª–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—ñ (121 –∑–∞–ø–∏—Å)")
    print("   –î–ª—è –∫—Ä–∞—â–æ—ó —Ç–æ—á–Ω–æ—Å—Ç—ñ –Ω–∞–∫–æ–ø–∏—á—É–π –±—ñ–ª—å—à–µ –¥–∞–Ω–∏—Ö (500+ –∑–∞–ø–∏—Å—ñ–≤)")
    print("=" * 60)

if __name__ == "__main__":
    test_model_training()