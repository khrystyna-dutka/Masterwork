# ml-service/data/preprocessor.py
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import joblib
import os
from config import Config

class DataPreprocessor:
    """–ö–ª–∞—Å –¥–ª—è –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∏ —Ç–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö"""
    
    def __init__(self, district_id):
        self.district_id = district_id
        self.scaler = MinMaxScaler()
        self.scaler_path = os.path.join(Config.MODEL_PATH, f'scaler_{district_id}.pkl')
        
        # –ö–æ–ª–æ–Ω–∫–∏ —è–∫—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
        self.feature_columns = [
            'pm25', 'temperature', 'humidity', 
            'pm10', 'no2', 'so2', 'co', 'o3'
        ]
    
    def prepare_data(self, df):
        """
        –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ –¥–ª—è –º–æ–¥–µ–ª—ñ
        
        Args:
            df: DataFrame –∑ —Å–∏—Ä–∏–º–∏ –¥–∞–Ω–∏–º–∏
        
        Returns:
            DataFrame –∑ –ø—ñ–¥–≥–æ—Ç–æ–≤–∞–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
        """
        # –ö–æ–ø—ñ—é—î–º–æ —â–æ–± –Ω–µ –∑–º—ñ–Ω—é–≤–∞—Ç–∏ –æ—Ä–∏–≥—ñ–Ω–∞–ª
        data = df.copy()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ measured_at –≤ datetime —è–∫—â–æ —Ç—Ä–µ–±–∞
        if 'measured_at' in data.columns:
            data['measured_at'] = pd.to_datetime(data['measured_at'])
            data = data.sort_values('measured_at')
        
        # –ó–∞–ø–æ–≤–Ω–∏—Ç–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        for col in self.feature_columns:
            if col in data.columns:
                data[col] = data[col].fillna(data[col].mean())
            else:
                # –Ø–∫—â–æ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ–º–∞—î - –¥–æ–¥–∞—Ç–∏ –∑ –Ω—É–ª—å–æ–≤–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
                data[col] = 0
        
        # –í–∏–±—Ä–∞—Ç–∏ —Ç—ñ–ª—å–∫–∏ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É
        prepared = data[self.feature_columns].copy()
        
        print(f"‚úÖ –î–∞–Ω—ñ –ø—ñ–¥–≥–æ—Ç–æ–≤–∞–Ω–æ: {len(prepared)} –∑–∞–ø–∏—Å—ñ–≤, {len(self.feature_columns)} –æ–∑–Ω–∞–∫")
        return prepared
    
    def normalize_data(self, data, fit=True):
        """
        –ù–æ—Ä–º–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ
        
        Args:
            data: numpy array –∞–±–æ DataFrame
            fit: True –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è scaler, False –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∑–±–µ—Ä–µ–∂–µ–Ω–æ–≥–æ
        
        Returns:
            –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ
        """
        if fit:
            # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è scaler
            normalized = self.scaler.fit_transform(data)
            # –ó–±–µ—Ä–µ–≥—Ç–∏ scaler
            joblib.dump(self.scaler, self.scaler_path)
            print(f"üíæ Scaler –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {self.scaler_path}")
        else:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π scaler
            if os.path.exists(self.scaler_path):
                self.scaler = joblib.load(self.scaler_path)
                normalized = self.scaler.transform(data)
            else:
                raise Exception(f"Scaler –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {self.scaler_path}. –ü–æ—Ç—Ä—ñ–±–Ω–æ —Å–ø–æ—á–∞—Ç–∫—É –Ω–∞—Ç—Ä–µ–Ω—É–≤–∞—Ç–∏ –º–æ–¥–µ–ª—å.")
        
        return normalized
    
    def inverse_transform(self, data):
        """
        –ü–æ–≤–µ—Ä–Ω—É—Ç–∏ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ –¥–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±—É
        
        Args:
            data: –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ
        
        Returns:
            –î–µ–Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ
        """
        if not os.path.exists(self.scaler_path):
            raise Exception(f"Scaler –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {self.scaler_path}")
        
        self.scaler = joblib.load(self.scaler_path)
        return self.scaler.inverse_transform(data)
    
    def create_sequences(self, data, sequence_length):
        """
        –°—Ç–≤–æ—Ä–∏—Ç–∏ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ –¥–ª—è LSTM (–°–¢–ê–†–ò–ô –º–µ—Ç–æ–¥ - –¥–ª—è —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ)
        
        Args:
            data: –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ
            sequence_length: –î–æ–≤–∂–∏–Ω–∞ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ
        
        Returns:
            X: –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ (samples, sequence_length, features)
            y: —Ü—ñ–ª—å–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è PM2.5
        """
        X, y = [], []
        
        for i in range(len(data) - sequence_length):
            X.append(data[i:i + sequence_length])
            # PM2.5 –Ω–∞ –ø–µ—Ä—à—ñ–π –ø–æ–∑–∏—Ü—ñ—ó
            y.append(data[i + sequence_length, 0])
        
        return np.array(X), np.array(y)
    
    def create_multi_output_sequences(self, data, sequence_length):
        """
        –°—Ç–≤–æ—Ä–∏—Ç–∏ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ –¥–ª—è multi-output LSTM
        
        Args:
            data: –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ
            sequence_length: –î–æ–≤–∂–∏–Ω–∞ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ
        
        Returns:
            X: –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ (samples, sequence_length, features)
            y_dict: —Å–ª–æ–≤–Ω–∏–∫ –∑ —Ü—ñ–ª—å–æ–≤–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—É
        """
        X = []
        y_pm25, y_pm10, y_no2, y_so2, y_co, y_o3 = [], [], [], [], [], []
        
        for i in range(len(data) - sequence_length):
            X.append(data[i:i + sequence_length])
            
            # –¶—ñ–ª—å–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è (–Ω–∞—Å—Ç—É–ø–Ω–∞ —Ç–æ—á–∫–∞ –ø—ñ—Å–ª—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ)
            next_point = data[i + sequence_length]
            
            # –ü–æ–∑–∏—Ü—ñ—ó –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –∑–≥—ñ–¥–Ω–æ self.feature_columns:
            # 0: pm25, 1: temperature, 2: humidity, 
            # 3: pm10, 4: no2, 5: so2, 6: co, 7: o3
            y_pm25.append(next_point[0])
            y_pm10.append(next_point[3])
            y_no2.append(next_point[4])
            y_so2.append(next_point[5])
            y_co.append(next_point[6])
            y_o3.append(next_point[7])
        
        X = np.array(X)
        
        y_dict = {
            'pm25': np.array(y_pm25),
            'pm10': np.array(y_pm10),
            'no2': np.array(y_no2),
            'so2': np.array(y_so2),
            'co': np.array(y_co),
            'o3': np.array(y_o3)
        }
        
        print(f"‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–æ {len(X)} –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π –∑ 6 –≤–∏—Ö–æ–¥–∞–º–∏")
        return X, y_dict
    
    def get_scaler_info(self):
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ scaler"""
        info = {
            'exists': os.path.exists(self.scaler_path),
            'path': self.scaler_path,
            'feature_columns': self.feature_columns
        }
        
        if info['exists']:
            scaler = joblib.load(self.scaler_path)
            info['data_min'] = scaler.data_min_.tolist()
            info['data_max'] = scaler.data_max_.tolist()
        
        return info