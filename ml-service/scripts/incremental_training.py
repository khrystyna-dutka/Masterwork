# ml-service/scripts/incremental_training.py
"""
–Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è: –¥–æ—Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –Ω–∞ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
"""
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.db_helper import DatabaseHelper
from models.lstm_model import LSTMForecastModel
from config import Config
import numpy as np
from datetime import datetime

def incremental_train_district(district_id, min_samples=50, epochs=5):
    """–Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ä–∞–π–æ–Ω—É"""
    
    db = DatabaseHelper()
    conn = db.get_connection()
    cursor = conn.cursor()
    
    print(f"\nüìç –†–∞–π–æ–Ω {district_id}:")
    
    try:
        # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –∫—ñ–ª—å–∫—ñ—Å—Ç—å
        cursor.execute("""
            SELECT COUNT(*)
            FROM training_feedback
            WHERE district_id = %s AND used_for_training = FALSE
        """, (district_id,))
        
        unused_count = cursor.fetchone()[0]
        print(f"   üìä –ù–µ–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤: {unused_count}")
        
        if unused_count < min_samples:
            print(f"   ‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–∏—Ö (–ø–æ—Ç—Ä—ñ–±–Ω–æ –º—ñ–Ω—ñ–º—É–º {min_samples})")
            return False
        
        # –û—Ç—Ä–∏–º–∞—Ç–∏ –ø—Ä–∏–∫–ª–∞–¥–∏
        cursor.execute("""
            SELECT 
                predicted_pm25, predicted_pm10, predicted_no2, predicted_so2, predicted_co, predicted_o3,
                actual_pm25, actual_pm10, actual_no2, actual_so2, actual_co, actual_o3
            FROM training_feedback
            WHERE district_id = %s AND used_for_training = FALSE
            ORDER BY created_at
            LIMIT 1000
        """, (district_id,))
        
        feedback_data = cursor.fetchall()
        print(f"   üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(feedback_data)} –ø—Ä–∏–∫–ª–∞–¥—ñ–≤")
        
        # –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ
        X_new = []
        y_new = {'pm25': [], 'pm10': [], 'no2': [], 'so2': [], 'co': [], 'o3': []}
        
        for row in feedback_data:
            pred = list(row[:6])
            actual = list(row[6:])
            
            # –°—Ç–≤–æ—Ä–∏—Ç–∏ —Ñ–µ–π–∫–æ–≤—É –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å
            full_vector = pred[:1] + [0.5, 0.5] + pred[1:]
            fake_sequence = np.tile(full_vector, (Config.SEQUENCE_LENGTH, 1))
            X_new.append(fake_sequence)
            
            # y - –ö–û–ù–í–ï–†–¢–£–í–ê–¢–ò –í FLOAT!
            y_new['pm25'].append(float(actual[0]))
            y_new['pm10'].append(float(actual[1]))
            y_new['no2'].append(float(actual[2]))
            y_new['so2'].append(float(actual[3]))
            y_new['co'].append(float(actual[4]))
            y_new['o3'].append(float(actual[5]))
        
        X_new = np.array(X_new, dtype=np.float32)
        y_new = {k: np.array(v, dtype=np.float32) for k, v in y_new.items()}
        
        print(f"   üìê –§–æ—Ä–º–∞ X: {X_new.shape}, dtype: {X_new.dtype}")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å
        model = LSTMForecastModel(district_id)
        if not model.load_model():
            print("   ‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞!")
            return False
        
        print("   ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞")
        
        # –î–æ—Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
        print(f"   üîÑ –î–æ—Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è ({epochs} –µ–ø–æ—Ö)...")
        
        import tensorflow as tf
        model.model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
            loss={'pm25': 'mse', 'pm10': 'mse', 'no2': 'mse', 'so2': 'mse', 'co': 'mse', 'o3': 'mse'}
        )
        
        history = model.model.fit(
            X_new, y_new,
            epochs=epochs,
            batch_size=min(16, len(X_new)),
            verbose=0
        )
        
        final_loss = history.history['loss'][-1]
        print(f"   ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ! Loss: {final_loss:.4f}")
        
        # –ó–±–µ—Ä–µ–≥—Ç–∏
        model.model.save(model.model_path)
        print(f"   üíæ –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–∞")
        
        # –ü–æ–∑–Ω–∞—á–∏—Ç–∏
        cursor.execute("""
            UPDATE training_feedback
            SET used_for_training = TRUE
            WHERE district_id = %s AND used_for_training = FALSE
        """, (district_id,))
        
        conn.commit()
        print(f"   ‚úÖ –ü–æ–∑–Ω–∞—á–µ–Ω–æ {cursor.rowcount} –∑–∞–ø–∏—Å—ñ–≤")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        conn.rollback()
        return False
    finally:
        cursor.close()
        conn.close()

def incremental_train_all(min_samples=50, epochs=5):
    """–Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è –¥–ª—è –≤—Å—ñ—Ö —Ä–∞–π–æ–Ω—ñ–≤"""
    
    print("=" * 70)
    print("üß† –Ü–ù–ö–†–ï–ú–ï–ù–¢–ê–õ–¨–ù–ï –ù–ê–í–ß–ê–ù–ù–Ø –ú–û–î–ï–õ–ï–ô")
    print("=" * 70)
    print(f"üïê –ß–∞—Å: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä–∏: min_samples={min_samples}, epochs={epochs}")
    
    success_count = sum(
        1 for district in Config.DISTRICTS 
        if incremental_train_district(district['id'], min_samples, epochs)
    )
    
    print("\n" + "=" * 70)
    print(f"‚úÖ –û–ù–û–í–õ–ï–ù–û –ú–û–î–ï–õ–ï–ô: {success_count}/{len(Config.DISTRICTS)}")
    
    if success_count > 0:
        print(f"\nüéâ –ú–æ–¥–µ–ª—ñ —Å—Ç–∞–ª–∏ —Ç–æ—á–Ω—ñ—à–∏–º–∏!")
        print(f"üí° Feedback —Ü–∏–∫–ª –ø—Ä–∞—Ü—é—î!")
    
    print("=" * 70)

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='–Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è')
    parser.add_argument('--min-samples', type=int, default=50)
    parser.add_argument('--epochs', type=int, default=5)
    
    args = parser.parse_args()
    incremental_train_all(min_samples=args.min_samples, epochs=args.epochs)