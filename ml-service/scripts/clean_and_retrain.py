# ml-service/scripts/clean_and_retrain.py
"""
–û—á–∏—Å—Ç–∏—Ç–∏ —Å—Ç–∞—Ä—ñ –¥–∞–Ω—ñ —Ç–∞ –ø–µ—Ä–µ–Ω–∞–≤—á–∏—Ç–∏ –º–æ–¥–µ–ª—ñ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.db_helper import DatabaseHelper
from data.preprocessor import DataPreprocessor
from models.lstm_model import LSTMForecastModel
from config import Config
from sklearn.model_selection import train_test_split
import shutil

def clean_old_data():
    """–û—á–∏—Å—Ç–∏—Ç–∏ —Å—Ç–∞—Ä—ñ feedback —Ç–∞ –º–æ–¥–µ–ª—ñ"""
    
    print("=" * 70)
    print("üßπ –û–ß–ò–©–ï–ù–ù–Ø –°–¢–ê–†–ò–• –î–ê–ù–ò–•")
    print("=" * 70)
    
    # 1. –û—á–∏—Å—Ç–∏—Ç–∏ feedback
    db = DatabaseHelper()
    conn = db.get_connection()
    cursor = conn.cursor()
    
    cursor.execute("SELECT COUNT(*) FROM training_feedback")
    old_count = cursor.fetchone()[0]
    
    print(f"\nüìä –°—Ç–∞—Ä–∏—Ö feedback: {old_count}")
    
    if old_count > 0:
        cursor.execute("DELETE FROM training_feedback")
        conn.commit()
        print(f"‚úÖ –í–∏–¥–∞–ª–µ–Ω–æ {old_count} —Å—Ç–∞—Ä–∏—Ö feedback")
    
    cursor.close()
    conn.close()
    
    # 2. –í–∏–¥–∞–ª–∏—Ç–∏ —Å—Ç–∞—Ä—ñ –º–æ–¥–µ–ª—ñ
    models_path = Config.MODEL_PATH
    if os.path.exists(models_path):
        print(f"\nüìÅ –û—á–∏—â–µ–Ω–Ω—è –ø–∞–ø–∫–∏ –º–æ–¥–µ–ª–µ–π: {models_path}")
        for file in os.listdir(models_path):
            file_path = os.path.join(models_path, file)
            try:
                if os.path.isfile(file_path):
                    os.unlink(file_path)
                    print(f"   üóëÔ∏è  –í–∏–¥–∞–ª–µ–Ω–æ: {file}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  –ü–æ–º–∏–ª–∫–∞ –≤–∏–¥–∞–ª–µ–Ω–Ω—è {file}: {e}")
    
    print("\n‚úÖ –û—á–∏—â–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("=" * 70)

def train_all_districts_properly():
    """–ù–∞–≤—á–∏—Ç–∏ –≤—Å—ñ —Ä–∞–π–æ–Ω–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ"""
    
    print("\n" + "=" * 70)
    print("üéì –ù–ê–í–ß–ê–ù–ù–Ø –ú–û–î–ï–õ–ï–ô –î–õ–Ø –í–°–Ü–• –†–ê–ô–û–ù–Ü–í")
    print("=" * 70)
    
    db = DatabaseHelper()
    results = []
    
    for district in Config.DISTRICTS:
        district_id = district['id']
        district_name = district['name']
        
        print(f"\n{'=' * 70}")
        print(f"üìç –†–ê–ô–û–ù {district_id}: {district_name}")
        print(f"{'=' * 70}")
        
        try:
            # 1. –û—Ç—Ä–∏–º–∞—Ç–∏ –¥–∞–Ω—ñ
            print("\n1Ô∏è‚É£ –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –ë–î...")
            df = db.get_historical_data(district_id, days=365)
            
            if len(df) < Config.SEQUENCE_LENGTH + 50:
                print(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö: {len(df)} –∑–∞–ø–∏—Å—ñ–≤ (–ø–æ—Ç—Ä—ñ–±–Ω–æ –º—ñ–Ω—ñ–º—É–º {Config.SEQUENCE_LENGTH + 50})")
                results.append({
                    'district_id': district_id,
                    'name': district_name,
                    'status': 'insufficient_data',
                    'records': len(df)
                })
                continue
            
            print(f"‚úÖ –û—Ç—Ä–∏–º–∞–Ω–æ {len(df)} –∑–∞–ø–∏—Å—ñ–≤")
            
            # 2. –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ
            print("\n2Ô∏è‚É£ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö...")
            preprocessor = DataPreprocessor(district_id)
            prepared_data = preprocessor.prepare_data(df)
            
            # 3. –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
            print("\n3Ô∏è‚É£ –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è...")
            normalized_data = preprocessor.normalize_data(prepared_data.values, fit=True)
            
            # 4. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π (multi-output)
            print("\n4Ô∏è‚É£ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π...")
            X, y_dict = preprocessor.create_multi_output_sequences(
                normalized_data, 
                Config.SEQUENCE_LENGTH
            )
            
            if len(X) == 0:
                print("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—å —Å—Ç–≤–æ—Ä–∏—Ç–∏ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ")
                results.append({
                    'district_id': district_id,
                    'name': district_name,
                    'status': 'no_sequences'
                })
                continue
            
            # 5. –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ train/val
            print("\n5Ô∏è‚É£ –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è train/val (80/20)...")
            split_idx = int(len(X) * 0.8)
            X_train, X_val = X[:split_idx], X[split_idx:]
            
            y_train_dict = {k: v[:split_idx] for k, v in y_dict.items()}
            y_val_dict = {k: v[split_idx:] for k, v in y_dict.items()}
            
            print(f"   Train: {len(X_train)} –∑—Ä–∞–∑–∫—ñ–≤")
            print(f"   Val: {len(X_val)} –∑—Ä–∞–∑–∫—ñ–≤")
            
            # 6. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
            print("\n6Ô∏è‚É£ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è Multi-Output LSTM –º–æ–¥–µ–ª—ñ...")
            model = LSTMForecastModel(district_id)
            model.build_model(input_shape=(X_train.shape[1], X_train.shape[2]))
            
            # 7. –í–∏–∑–Ω–∞—á–∏—Ç–∏ epochs –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö
            if len(X_train) < 100:
                epochs = 20
            elif len(X_train) < 300:
                epochs = 30
            else:
                epochs = 50
            
            print(f"\n7Ô∏è‚É£ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è ({epochs} –µ–ø–æ—Ö)...")
            print("   ‚è≥ –¶–µ –º–æ–∂–µ –∑–∞–π–Ω—è—Ç–∏ 2-5 —Ö–≤–∏–ª–∏–Ω...")
            
            history = model.train(
                X_train, y_train_dict,
                X_val, y_val_dict,
                epochs=epochs,
                batch_size=16 if len(X_train) > 100 else 8
            )
            
            # 8. –û—Ü—ñ–Ω–∫–∞
            print("\n8Ô∏è‚É£ –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ...")
            metrics = model.evaluate(X_val, y_val_dict)
            
            final_loss = history.history['loss'][-1]
            
            print(f"\n‚úÖ –ù–∞–≤—á–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            print(f"   üìâ Final Loss: {final_loss:.4f}")
            print(f"   üìä Avg MAE: {metrics.get('avg_mae', 0):.4f}")
            print(f"   üíæ –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–∞: {model.model_path}")
            print(f"   üíæ Scaler –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π: {preprocessor.scaler_path}")
            
            results.append({
                'district_id': district_id,
                'name': district_name,
                'status': 'success',
                'records': len(df),
                'sequences': len(X_train),
                'epochs': epochs,
                'final_loss': final_loss,
                'avg_mae': metrics.get('avg_mae', 0)
            })
            
        except Exception as e:
            print(f"\n‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            results.append({
                'district_id': district_id,
                'name': district_name,
                'status': 'error',
                'error': str(e)
            })
    
    # –ü—ñ–¥—Å—É–º–æ–∫
    print("\n" + "=" * 70)
    print("üìä –ü–Ü–î–°–£–ú–û–ö –ù–ê–í–ß–ê–ù–ù–Ø")
    print("=" * 70)
    
    for result in results:
        status_icon = {
            'success': '‚úÖ',
            'insufficient_data': '‚ö†Ô∏è',
            'no_sequences': '‚ùå',
            'error': '‚ùå'
        }.get(result['status'], '‚ùì')
        
        print(f"\n{status_icon} –†–∞–π–æ–Ω {result['district_id']}: {result['name']}")
        print(f"   –°—Ç–∞—Ç—É—Å: {result['status']}")
        
        if result['status'] == 'success':
            print(f"   üìä –ó–∞–ø–∏—Å—ñ–≤: {result['records']}")
            print(f"   üîÑ –ü–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π: {result['sequences']}")
            print(f"   üìà –ï–ø–æ—Ö: {result['epochs']}")
            print(f"   üìâ Loss: {result['final_loss']:.4f}")
            print(f"   üéØ MAE: {result['avg_mae']:.4f}")
        elif result['status'] == 'insufficient_data':
            print(f"   üìä –ó–∞–ø–∏—Å—ñ–≤: {result['records']} (–∑–∞–º–∞–ª–æ)")
        elif 'error' in result:
            print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞: {result['error']}")
    
    success_count = sum(1 for r in results if r['status'] == 'success')
    
    print("\n" + "=" * 70)
    print(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ –Ω–∞–≤—á–µ–Ω–æ: {success_count}/6 —Ä–∞–π–æ–Ω—ñ–≤")
    print("=" * 70)
    
    return success_count > 0

if __name__ == "__main__":
    print("üöÄ –ü–û–í–ù–ï –ü–ï–†–ï–ù–ê–í–ß–ê–ù–ù–Ø –ú–û–î–ï–õ–ï–ô\n")
    
    # –ö—Ä–æ–∫ 1: –û—á–∏—Å—Ç–∏—Ç–∏
    clean_old_data()
    
    # –ö—Ä–æ–∫ 2: –ù–∞–≤—á–∏—Ç–∏ –∑–∞–Ω–æ–≤–æ
    success = train_all_districts_properly()
    
    if success:
        print("\nüí° –ù–ê–°–¢–£–ü–ù–Ü –ö–†–û–ö–ò:")
        print("   1. –°—Ç–≤–æ—Ä–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏: python scripts/generate_forecasts_all.py")
        print("   2. –ó—ñ–±–µ—Ä–∏ feedback: python scripts/collect_feedback.py")
        print("   3. –ó–∞–ø—É—Å—Ç–∏ –∞–≤—Ç–æ–Ω–∞–≤—á–∞–Ω–Ω—è: python scripts/auto_learning_scheduler.py")
        print("\nüéØ –í—ñ–¥–∫—Ä–∏–π dashboard: http://localhost:5001/dashboard")