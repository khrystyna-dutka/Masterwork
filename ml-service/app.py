from flask import Flask, jsonify, request
from flask_cors import CORS
from config import Config
from utils.db_helper import DatabaseHelper
from data.preprocessor import DataPreprocessor
from models.lstm_model import LSTMForecastModel
import os
import pandas as pd
from datetime import datetime, timedelta
import traceback

app = Flask(__name__)
CORS(app)

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
os.makedirs(Config.MODEL_PATH, exist_ok=True)
db = DatabaseHelper()

@app.route('/', methods=['GET'])
def index():
    """–ì–æ–ª–æ–≤–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ API"""
    return jsonify({
        'success': True,
        'message': 'EcoLviv ML Service is running! ü§ñ',
        'version': '1.0.0',
        'endpoints': {
            'health': '/health',
            'forecast': '/api/forecast/<district_id>',
            'forecast_all': '/api/forecast/all',
            'train': '/api/train/<district_id>',
            'train_all': '/api/train/all',
            'model_info': '/api/model/<district_id>',
            'stats': '/api/stats/<district_id>'
        }
    })

@app.route('/health', methods=['GET'])
def health():
    """Health check"""
    try:
        db_status = db.test_connection()
        return jsonify({
            'status': 'healthy' if db_status else 'unhealthy',
            'service': 'ml-service',
            'database': 'connected' if db_status else 'disconnected',
            'timestamp': datetime.now().isoformat()
        }), 200 if db_status else 503
    except Exception as e:
        return jsonify({
            'status': 'unhealthy',
            'error': str(e)
        }), 503

@app.route('/api/forecast/<int:district_id>', methods=['GET'])
def get_forecast(district_id):
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Ä–∞–π–æ–Ω—É
    
    Query params:
        hours (int): –ö—ñ–ª—å–∫—ñ—Å—Ç—å –≥–æ–¥–∏–Ω –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É (default: 24)
        save (bool): –ó–±–µ—Ä–µ–≥—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑ –≤ –ë–î (default: true)
    """
    try:
        hours = request.args.get('hours', Config.FORECAST_HOURS, type=int)
        save_to_db = request.args.get('save', 'true').lower() == 'true'
        
        # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
        if district_id < 1 or district_id > 6:
            return jsonify({
                'success': False,
                'error': 'Invalid district_id. Must be between 1 and 6'
            }), 400
        
        if hours < 1 or hours > 168:
            return jsonify({
                'success': False,
                'error': 'Invalid hours. Must be between 1 and 168'
            }), 400
        
        print(f"\nüìç –ó–∞–ø–∏—Ç –ø—Ä–æ–≥–Ω–æ–∑—É –¥–ª—è —Ä–∞–π–æ–Ω—É {district_id} –Ω–∞ {hours} –≥–æ–¥–∏–Ω")
        
        # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å
        model = LSTMForecastModel(district_id)
        if not model.load_model():
            return jsonify({
                'success': False,
                'error': f'Model not found for district {district_id}. Please train the model first.',
                'hint': f'POST /api/train/{district_id}'
            }), 404
        
        # 2. –û—Ç—Ä–∏–º–∞—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—ñ –¥–∞–Ω—ñ
        df = db.get_latest_data(district_id, hours=Config.SEQUENCE_LENGTH)
        
        if len(df) < Config.SEQUENCE_LENGTH:
            return jsonify({
                'success': False,
                'error': f'Not enough data. Need at least {Config.SEQUENCE_LENGTH} records.',
                'available': len(df)
            }), 400
        
        # 3. –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ
        preprocessor = DataPreprocessor(district_id)
        prepared_data = preprocessor.prepare_data(df)
        
        if prepared_data is None or prepared_data.empty:
            return jsonify({
                'success': False,
                'error': 'Data preparation failed'
            }), 500
        
        # 4. –ù–æ—Ä–º–∞–ª—ñ–∑—É–≤–∞—Ç–∏
        normalized_data = preprocessor.normalize_data(prepared_data.values, fit=False)
        
        # 5. –í–∑—è—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—é –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å
        last_sequence = normalized_data[-Config.SEQUENCE_LENGTH:]
        
        # 6. –ü—Ä–æ–≥–Ω–æ–∑
        predictions = model.predict_future(last_sequence, n_hours=hours)
        
        # 7. –ü–æ–≤–µ—Ä–Ω—É—Ç–∏ –¥–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±—É
        predicted_pm25 = preprocessor.inverse_transform_predictions(predictions)
        
        # 8. –°—Ç–≤–æ—Ä–∏—Ç–∏ DataFrame –∑ –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏
        last_timestamp = df['measured_at'].max()
        forecast_times = [last_timestamp + timedelta(hours=i+1) for i in range(hours)]
        
        forecasts = []
        for i, (time, pm25) in enumerate(zip(forecast_times, predicted_pm25)):
            aqi, aqi_status = preprocessor.calculate_aqi_from_pm25(pm25)
            
            forecasts.append({
                'hour': i + 1,
                'measured_at': time.isoformat(),
                'pm25': round(float(pm25), 2),
                'aqi': int(aqi),
                'aqi_status': aqi_status,
                'confidence_level': 0.85
            })
        
        # 9. –ó–±–µ—Ä–µ–≥—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏ –≤ –ë–î
        if save_to_db:
            forecast_df = pd.DataFrame(forecasts)
            forecast_df['measured_at'] = pd.to_datetime(forecast_df['measured_at'])
            
            # –î–æ–¥–∞—î–º–æ —ñ–Ω—à—ñ –ø–æ–ª—è –¥–ª—è –ë–î
            forecast_df['pm10'] = None
            forecast_df['no2'] = None
            forecast_df['so2'] = None
            forecast_df['co'] = None
            forecast_df['o3'] = None
            forecast_df['temperature'] = None
            forecast_df['humidity'] = None
            forecast_df['pressure'] = None
            forecast_df['wind_speed'] = None
            forecast_df['wind_direction'] = None
            
            db.save_forecast(district_id, forecast_df)
        
        print(f"‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ —Å—Ç–≤–æ—Ä–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ")
        
        return jsonify({
            'success': True,
            'district_id': district_id,
            'forecast_hours': hours,
            'forecasts': forecasts,
            'generated_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/forecast/all', methods=['GET'])
def get_forecast_all():
    """–û—Ç—Ä–∏–º–∞—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏ –¥–ª—è –≤—Å—ñ—Ö —Ä–∞–π–æ–Ω—ñ–≤"""
    try:
        hours = request.args.get('hours', Config.FORECAST_HOURS, type=int)
        save_to_db = request.args.get('save', 'true').lower() == 'true'
        
        results = []
        errors = []
        
        for district in Config.DISTRICTS:
            district_id = district['id']
            try:
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ç–æ–π —Å–∞–º–∏–π –∫–æ–¥ —â–æ –π –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ä–∞–π–æ–Ω—É
                model = LSTMForecastModel(district_id)
                if not model.load_model():
                    errors.append({
                        'district_id': district_id,
                        'district_name': district['name'],
                        'error': 'Model not found'
                    })
                    continue
                
                df = db.get_latest_data(district_id, hours=Config.SEQUENCE_LENGTH)
                
                if len(df) < Config.SEQUENCE_LENGTH:
                    errors.append({
                        'district_id': district_id,
                        'district_name': district['name'],
                        'error': 'Not enough data'
                    })
                    continue
                
                preprocessor = DataPreprocessor(district_id)
                prepared_data = preprocessor.prepare_data(df)
                normalized_data = preprocessor.normalize_data(prepared_data.values, fit=False)
                last_sequence = normalized_data[-Config.SEQUENCE_LENGTH:]
                predictions = model.predict_future(last_sequence, n_hours=hours)
                predicted_pm25 = preprocessor.inverse_transform_predictions(predictions)
                
                last_timestamp = df['measured_at'].max()
                forecast_times = [last_timestamp + timedelta(hours=i+1) for i in range(hours)]
                
                forecasts = []
                for i, (time, pm25) in enumerate(zip(forecast_times, predicted_pm25)):
                    aqi, aqi_status = preprocessor.calculate_aqi_from_pm25(pm25)
                    forecasts.append({
                        'hour': i + 1,
                        'measured_at': time.isoformat(),
                        'pm25': round(float(pm25), 2),
                        'aqi': int(aqi),
                        'aqi_status': aqi_status
                    })
                
                if save_to_db:
                    forecast_df = pd.DataFrame(forecasts)
                    forecast_df['measured_at'] = pd.to_datetime(forecast_df['measured_at'])
                    forecast_df['pm10'] = None
                    forecast_df['no2'] = None
                    forecast_df['so2'] = None
                    forecast_df['co'] = None
                    forecast_df['o3'] = None
                    forecast_df['temperature'] = None
                    forecast_df['humidity'] = None
                    forecast_df['pressure'] = None
                    forecast_df['wind_speed'] = None
                    forecast_df['wind_direction'] = None
                    db.save_forecast(district_id, forecast_df)
                
                results.append({
                    'district_id': district_id,
                    'district_name': district['name'],
                    'forecasts': forecasts
                })
                
            except Exception as e:
                errors.append({
                    'district_id': district_id,
                    'district_name': district['name'],
                    'error': str(e)
                })
        
        return jsonify({
            'success': True,
            'total_districts': len(Config.DISTRICTS),
            'successful': len(results),
            'failed': len(errors),
            'results': results,
            'errors': errors if errors else None,
            'generated_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/train/<int:district_id>', methods=['POST'])
def train_model(district_id):
    """–¢—Ä–µ–Ω—É–≤–∞—Ç–∏ –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–∞–π–æ–Ω—É"""
    try:
        # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
        if district_id < 1 or district_id > 6:
            return jsonify({
                'success': False,
                'error': 'Invalid district_id'
            }), 400
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑ request
        days = request.json.get('days', 30) if request.json else 30
        epochs = request.json.get('epochs', 50) if request.json else 50
        
        print(f"\nüéØ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –¥–ª—è —Ä–∞–π–æ–Ω—É {district_id}")
        
        # 1. –û—Ç—Ä–∏–º–∞—Ç–∏ –¥–∞–Ω—ñ
        df = db.get_historical_data(district_id, days=days)
        
        if len(df) < Config.SEQUENCE_LENGTH + 10:
            return jsonify({
                'success': False,
                'error': f'Not enough data. Need at least {Config.SEQUENCE_LENGTH + 10} records.',
                'available': len(df)
            }), 400
        
        # 2. –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ
        preprocessor = DataPreprocessor(district_id)
        prepared_data = preprocessor.prepare_data(df)
        normalized_data = preprocessor.normalize_data(prepared_data.values, fit=True)
        
        # 3. –°—Ç–≤–æ—Ä–∏—Ç–∏ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç—ñ
        X, y = preprocessor.create_sequences(normalized_data, Config.SEQUENCE_LENGTH)
        
        # 4. –†–æ–∑–¥—ñ–ª–∏—Ç–∏ –Ω–∞ train/val
        split_idx = int(len(X) * 0.8)
        X_train, X_val = X[:split_idx], X[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]
        
        # 5. –¢—Ä–µ–Ω—É–≤–∞—Ç–∏ –º–æ–¥–µ–ª—å
        model = LSTMForecastModel(district_id)
        model.build_model(input_shape=(X_train.shape[1], X_train.shape[2]))
        
        history = model.train(
            X_train, y_train,
            X_val, y_val,
            epochs=epochs,
            batch_size=16
        )
        
        # 6. –û—Ü—ñ–Ω–∏—Ç–∏ –º–æ–¥–µ–ª—å
        metrics = model.evaluate(X_val, y_val)
        
        return jsonify({
            'success': True,
            'district_id': district_id,
            'training_records': len(df),
            'sequences_created': len(X),
            'epochs_trained': len(history.history['loss']),
            'metrics': metrics,
            'model_path': model.model_path,
            'trained_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/train/all', methods=['POST'])
def train_all_models():
    """–¢—Ä–µ–Ω—É–≤–∞—Ç–∏ –º–æ–¥–µ–ª—ñ –¥–ª—è –≤—Å—ñ—Ö —Ä–∞–π–æ–Ω—ñ–≤"""
    try:
        days = request.json.get('days', 30) if request.json else 30
        epochs = request.json.get('epochs', 50) if request.json else 50
        
        results = []
        errors = []
        
        for district in Config.DISTRICTS:
            district_id = district['id']
            try:
                print(f"\nüéØ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è —Ä–∞–π–æ–Ω—É {district_id}: {district['name']}")
                
                df = db.get_historical_data(district_id, days=days)
                
                if len(df) < Config.SEQUENCE_LENGTH + 10:
                    errors.append({
                        'district_id': district_id,
                        'district_name': district['name'],
                        'error': 'Not enough data'
                    })
                    continue
                
                preprocessor = DataPreprocessor(district_id)
                prepared_data = preprocessor.prepare_data(df)
                normalized_data = preprocessor.normalize_data(prepared_data.values, fit=True)
                X, y = preprocessor.create_sequences(normalized_data, Config.SEQUENCE_LENGTH)
                
                split_idx = int(len(X) * 0.8)
                X_train, X_val = X[:split_idx], X[split_idx:]
                y_train, y_val = y[:split_idx], y[split_idx:]
                
                model = LSTMForecastModel(district_id)
                model.build_model(input_shape=(X_train.shape[1], X_train.shape[2]))
                model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=16)
                
                metrics = model.evaluate(X_val, y_val)
                
                results.append({
                    'district_id': district_id,
                    'district_name': district['name'],
                    'training_records': len(df),
                    'metrics': metrics
                })
                
            except Exception as e:
                errors.append({
                    'district_id': district_id,
                    'district_name': district['name'],
                    'error': str(e)
                })
        
        return jsonify({
            'success': True,
            'total_districts': len(Config.DISTRICTS),
            'successful': len(results),
            'failed': len(errors),
            'results': results,
            'errors': errors if errors else None,
            'trained_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/model/<int:district_id>', methods=['GET'])
def get_model_info(district_id):
    """–û—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –º–æ–¥–µ–ª—å"""
    try:
        if district_id < 1 or district_id > 6:
            return jsonify({
                'success': False,
                'error': 'Invalid district_id'
            }), 400
        
        model = LSTMForecastModel(district_id)
        info = model.get_model_info()
        
        # –î–æ–¥–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∞–Ω–∏—Ö
        stats = db.get_data_stats(district_id)
        info['data_stats'] = stats
        
        return jsonify({
            'success': True,
            'model_info': info
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/stats/<int:district_id>', methods=['GET'])
def get_district_stats(district_id):
    """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–∞–π–æ–Ω—É"""
    try:
        if district_id < 1 or district_id > 6:
            return jsonify({
                'success': False,
                'error': 'Invalid district_id'
            }), 400
        
        stats = db.get_data_stats(district_id)
        
        return jsonify({
            'success': True,
            'district_id': district_id,
            'stats': stats
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

if __name__ == '__main__':
    print("\n" + "="*60)
    print("üöÄ Starting EcoLviv ML Service")
    print("="*60)
    print(f"üìç Port: {Config.FLASK_PORT}")
    print(f"üîß Debug: {Config.FLASK_DEBUG}")
    print(f"üíæ Model path: {Config.MODEL_PATH}")
    print("="*60 + "\n")
    
    app.run(
        host='0.0.0.0',
        port=Config.FLASK_PORT,
        debug=Config.FLASK_DEBUG
    )